{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60938a54-2569-4028-b02c-979edd8400be",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b61c13-980f-4a8f-88cf-0c792da896c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and Cnn1D class definition complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# We need to define the model architecture again so we can load the weights into it\n",
    "class Cnn1D(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Cnn1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=32, stride=4, padding=14),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=16, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=8, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=448, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=128, out_features=num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "print(\"Imports and Cnn1D class definition complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe413e-cfb8-4520-9565-98252b3c3b4d",
   "metadata": {},
   "source": [
    "## Load Artifacts\n",
    "This cell loads the trained model and the scaler that we saved earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8e3c3a-ee54-4748-9ea6-fdea5dbc226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and set to 'cuda' device.\n",
      "Scaler loaded: StandardScaler()\n",
      "Ready to make predictions.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Artifacts ---\n",
    "\n",
    "# Define paths to your artifacts within the streamlit_app folder\n",
    "APP_FOLDER_PATH = '../streamlit_app'\n",
    "MODEL_PATH = os.path.join(APP_FOLDER_PATH, 'best_1d_cnn_model.pth')\n",
    "SCALER_PATH = os.path.join(APP_FOLDER_PATH, 'standard_scaler.joblib')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = Cnn1D(num_classes=4).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# Define class names (ensure this order matches your label encoding)\n",
    "CLASS_NAMES = ['Ball Fault', 'Inner Race Fault', 'Normal', 'Outer Race Fault']\n",
    "\n",
    "\n",
    "print(f\"Model loaded and set to '{device}' device.\")\n",
    "print(f\"Scaler loaded: {scaler}\")\n",
    "print(\"Ready to make predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165d21d-1f6b-46e9-ba67-c6f04476c96f",
   "metadata": {},
   "source": [
    "## The Prediction Function\n",
    "This is the core function. It encapsulates the entire process from reading a file to making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d973d1-2dd2-45a8-88b4-17788b5c6ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function is defined.\n"
     ]
    }
   ],
   "source": [
    "def predict_signal(signal_path, model, scaler, device):\n",
    "    \"\"\"\n",
    "    Loads a signal from a CSV, preprocesses it, and returns the model's prediction.\n",
    "    \n",
    "    Args:\n",
    "        signal_path (str): The full path to the signal CSV file.\n",
    "        model (torch.nn.Module): The loaded PyTorch model.\n",
    "        scaler (StandardScaler): The loaded scikit-learn scaler.\n",
    "        device (torch.device): The device to run inference on ('cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing (predicted_class_name, probabilities_dict)\n",
    "    \"\"\"\n",
    "    # 1. Load the signal data\n",
    "    signal = pd.read_csv(signal_path, header=None).values.flatten().astype(np.float32)\n",
    "    \n",
    "    # 2. Preprocess: Segment, Scale, and Convert to Tensor\n",
    "    # We only analyze the first 2048 samples, as our model was trained on this size\n",
    "    if len(signal) < 2048:\n",
    "        return \"Error: Signal is too short. Needs at least 2048 samples.\", {}\n",
    "        \n",
    "    segment = signal[:2048]\n",
    "    \n",
    "    # The scaler expects a 2D array, so we reshape it\n",
    "    segment_scaled = scaler.transform(segment.reshape(1, -1))\n",
    "    \n",
    "    # Convert to a PyTorch tensor with the correct shape (1, 1, 2048)\n",
    "    segment_tensor = torch.tensor(segment_scaled, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 3. Make Prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(segment_tensor)\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get the top class\n",
    "        top_prob, top_class_idx = torch.max(probabilities, 1)\n",
    "        predicted_class_name = CLASS_NAMES[top_class_idx.item()]\n",
    "\n",
    "    # 4. Format probabilities for output\n",
    "    probabilities_dict = {CLASS_NAMES[i]: prob.item() for i, prob in enumerate(probabilities[0])}\n",
    "    \n",
    "    return predicted_class_name, probabilities_dict\n",
    "\n",
    "print(\"Prediction function is defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39fd99-e1b9-4a69-a82a-cff2f48ab1a4",
   "metadata": {},
   "source": [
    "## Test the Function\n",
    "Now, let's use the function to test the four sample signals we created at the end of `02_preprocessing_feature_engineering_and_augmentation.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45615a2-d9c5-494c-84e6-4fe036427a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prediction for: test_signal_normal.csv ---\n",
      "  Predicted Class: Normal\n",
      "  Confidence: 100.00%\n",
      "  Full Probabilities: {'Ball Fault': '0.00%', 'Inner Race Fault': '0.00%', 'Normal': '100.00%', 'Outer Race Fault': '0.00%'}\n",
      "------------------------------\n",
      "--- Prediction for: test_signal_irf.csv ---\n",
      "  Predicted Class: Inner Race Fault\n",
      "  Confidence: 100.00%\n",
      "  Full Probabilities: {'Ball Fault': '0.00%', 'Inner Race Fault': '100.00%', 'Normal': '0.00%', 'Outer Race Fault': '0.00%'}\n",
      "------------------------------\n",
      "--- Prediction for: test_signal_bf.csv ---\n",
      "  Predicted Class: Ball Fault\n",
      "  Confidence: 100.00%\n",
      "  Full Probabilities: {'Ball Fault': '100.00%', 'Inner Race Fault': '0.00%', 'Normal': '0.00%', 'Outer Race Fault': '0.00%'}\n",
      "------------------------------\n",
      "--- Prediction for: test_signal_orf.csv ---\n",
      "  Predicted Class: Outer Race Fault\n",
      "  Confidence: 100.00%\n",
      "  Full Probabilities: {'Ball Fault': '0.00%', 'Inner Race Fault': '0.00%', 'Normal': '0.00%', 'Outer Race Fault': '100.00%'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Test the Prediction Function ---\n",
    "\n",
    "# List the paths to your test signals\n",
    "test_signal_paths = [\n",
    "    os.path.join(APP_FOLDER_PATH, 'test_signal_normal.csv'),\n",
    "    os.path.join(APP_FOLDER_PATH, 'test_signal_irf.csv'),\n",
    "    os.path.join(APP_FOLDER_PATH, 'test_signal_bf.csv'),\n",
    "    os.path.join(APP_FOLDER_PATH, 'test_signal_orf.csv')\n",
    "]\n",
    "\n",
    "for path in test_signal_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    predicted_class, probs = predict_signal(path, model, scaler, device)\n",
    "    \n",
    "    print(f\"--- Prediction for: {filename} ---\")\n",
    "    if \"Error\" in predicted_class:\n",
    "        print(predicted_class)\n",
    "    else:\n",
    "        print(f\"  Predicted Class: {predicted_class}\")\n",
    "        # Find the confidence for the predicted class\n",
    "        confidence = probs[predicted_class]\n",
    "        print(f\"  Confidence: {confidence:.2%}\")\n",
    "        print(\"  Full Probabilities:\", {k: f\"{v:.2%}\" for k, v in probs.items()})\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507743e-aaec-47b6-b498-60320594d9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa50ba-2f68-42f0-adca-9bccb8378115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
